\documentclass[a4paper, 11pt]{article}
\usepackage[english]{babel}

\title{Kernel Methods and SVMs:
A convex optimization point of view}
\author{Gael Lederrey\\
  \and
Corentin Tallec}

\begin{document}
\maketitle
\begin{abstract}
  Kernel methods, and more specifically support vectors machines, are
  well known, well theorized and efficient machine learning tools. For
  years, they were presenting state of the art performances in many
  machine learning fields, before being overtaken by deep learning
  methods. They have the enormous advantage of being well understood
  theoretically, and most interestingly to belong to the class of
  convex optimization problems, which is clearly not the case of the
  latter.

  In this document, we aim at presenting the general framework of
  Kernel methods, to expose how they relate to convex optimization,
  and how their optimization can be undertaken in practice. Besides,
  we intend to give a more precise treatment of the support vectors
  machines special case.
\end{abstract}
\section{Kernel methods}
\subsection{Generalities}
\subsection{Kernel methods as convex optimization problems}
\subsection{From infinite to finite}
\section{Support vector machines: a special case}
\subsection{Generalities}
\subsection{Dual problem}
\subsection{A use case}
\end{document}
